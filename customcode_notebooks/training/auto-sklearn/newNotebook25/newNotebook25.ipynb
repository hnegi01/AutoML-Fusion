{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "# The variables below have to be included in the test cell in order to run the notebook manually.\n",
    "from init_sisense import sisense_conn\n",
    "cube_name = \"bank_churn\"\n",
    "additional_parameters = sisense_conn.load_additional_parameters(cube_name, table_name=\"bank_churn_train_auto_sklearn_ml\")\n",
    "# additional_parameters\n",
    "sisense_conn.set_parameters(cube_name=cube_name, additional_parameters=additional_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade sisense-automl\n",
    "!pip install mpld3\n",
    "!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sisense_automl import AutoMl\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "from numpy import savetxt, loadtxt\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)  ## to prevent scientific notation.\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import mpld3\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    ")\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input parameters from custom code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = sisense_conn.add_param[\"Dataset\"][\"table\"]\n",
    "objective = sisense_conn.add_param[\"Objective\"]\n",
    "target_column = sisense_conn.add_param[\"Target Column\"][\"column\"]\n",
    "drop_column = sisense_conn.add_param[\"Drop Feature\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from Elasticube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Sql Statement\n",
    "logical_sql1 = (f'SELECT * from [{table}] ')\n",
    "print(\"SQL Statement:\\n\" + logical_sql1)\n",
    "# Execute the SQL Statement\n",
    "logical_sql_res1 = sisense_conn.get_logical_sql(query=logical_sql1, \n",
    "                                               cube_name=cube_name,  # passed to notebook from build / Test Cell\n",
    "                                               count=None)  # limit the rows fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Known null representations needed since row from EC having null or empty values are represted as below in the list/array\n",
    "null_representations = ['N\\\\A', 'NA', 'N/A', '']\n",
    "column_names = logical_sql_res1['headers']\n",
    "values = logical_sql_res1['values']\n",
    "# Function to replace null representations\n",
    "def replace_nulls(data, null_representations):\n",
    "    return [[np.nan if v in null_representations else v for v in row] for row in data]\n",
    "\n",
    "# Clean the data\n",
    "values_cleaned = replace_nulls(values, null_representations)\n",
    "# Get Data\n",
    "df = pd.DataFrame(values_cleaned, columns = column_names)\n",
    "if drop_column != '0':\n",
    "    # Split the drop_column string into a list of column names\n",
    "    columns_to_drop = drop_column.split(',')\n",
    "    # Drop the specified columns\n",
    "    df = df.drop(columns_to_drop, axis=1)\n",
    "df.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create list of features for Widget\n",
    "widget_features = df.columns.tolist()\n",
    "\n",
    "# Remove the target column from the list\n",
    "if target_column in widget_features:\n",
    "    widget_features.remove(target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directory in Sisense to store files and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp = datetime.now()\n",
    "current_timestamp = current_timestamp.strftime('%Y%m%d%H%M%S')\n",
    "folder_path = f\"/opt/sisense/storage/notebooks/custom_code_notebooks/notebooks/automl/{table.split('.')[0]}/{current_timestamp}\"\n",
    "os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store EDA lcoally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df,\n",
    "                        title=\"Exploratory Data Analysis\",\n",
    "                        explorative=True,\n",
    "                        correlations={\n",
    "                            \"auto\": {\"calculate\": True},\n",
    "                            \"pearson\": {\"calculate\": True},\n",
    "                            \"spearman\": {\"calculate\": True},\n",
    "                            \"kendall\": {\"calculate\": True},\n",
    "                            \"phi_k\": {\"calculate\": True},\n",
    "                            \"cramers\": {\"calculate\": True},\n",
    "                        })\n",
    "profile.to_file(folder_path + '/eda.html')\n",
    "\n",
    "# profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For large datasets or those with class imbalance (where one class has significantly more records than others), itâ€™s important to train the model on a representative subset. Using stratified sampling ensures that the class distribution is preserved, improving data quality and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified_sample = df.groupby('Payment_Cat').apply(\n",
    "#     lambda x: x.sample(frac=0.01)\n",
    "# )\n",
    "\n",
    "# # Removing the extra index added by groupby()\n",
    "# stratified_sample = stratified_sample.droplevel(0)\n",
    "# stratified_sample.head()\n",
    "# stratified_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Model Training\n",
    "### Call automl class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Parameters:\n",
    "\n",
    "#### 1. `time_left_for_this_task`:\n",
    "This parameter defines the total time allowed for the entire AutoML task, including feature selection, model training, hyperparameter optimization, and model ensemble creation.\n",
    "\n",
    "- **Default**: `time_left_for_this_task=1800` (30 minutes).\n",
    "- **Usage**: If not specified, the AutoML process will have 30 minutes to complete. Increase this for larger datasets or more complex models.\n",
    "\n",
    "#### 2. `per_run_time_limit`:\n",
    "This parameter defines the maximum time allowed for each individual model training and validation run. It ensures that no single model will take more than the specified time to train and evaluate.\n",
    "\n",
    "- **Default**: `per_run_time_limit=360` (6 minutes).\n",
    "- **Usage**: Adjust this based on the complexity of the models or dataset. Increasing this might be useful for deeper models that require more training time.\n",
    "\n",
    "#### 3. `ensemble_size`:\n",
    "The number of models to include in the final ensemble. The ensemble combines the best models to create a more robust and accurate final model.\n",
    "\n",
    "- **Default**: `ensemble_size=5`.\n",
    "- **Usage**: A higher ensemble size can improve model accuracy but may also increase the computational cost and model complexity.\n",
    "\n",
    "#### 4. `n_jobs`:\n",
    "This parameter defines the number of CPU cores used for parallel model training. It controls the degree of parallelism to speed up training.\n",
    "\n",
    "- **Default**: `n_jobs=8`.\n",
    "- **Usage**: Set this according to the number of available CPU cores on your machine. A higher value allows more models to be trained simultaneously.\n",
    "\n",
    "### Summary of Default Values:\n",
    "- **time_left_for_this_task**: `1800` (30 minutes).\n",
    "- **per_run_time_limit**: `360` (6 minutes).\n",
    "- **ensemble_size**: `5`.\n",
    "- **n_jobs**: `8`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Using default parameters values:\n",
    "# automl = AutoMl(df, target_column, objective, folder_path) \n",
    "\n",
    "# Using custom parameters for all four optional parameters\n",
    "automl = AutoMl(df, target_column, objective, folder_path,\n",
    "                time_left_for_this_task=3600,\n",
    "                per_run_time_limit=360,\n",
    "                ensemble_size=5,\n",
    "                n_jobs=8)\n",
    "\n",
    "#print(automl.file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model Accuracy\n",
    "### Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = automl.file_name\n",
    "loaded_model = joblib.load(f\"{folder_path}/{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained model ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load numpy array from csv file\n",
    "X_test = pd.read_csv(f\"{folder_path}/X_test.csv\")\n",
    "y_test = pd.read_csv(f\"{folder_path}/y_test.csv\")\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Transformer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_pipeline = joblib.load(f\"{folder_path}/transformer_pipeline\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply feature engineering on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = transformer_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =loaded_model.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = {}\n",
    "metrics = []\n",
    "if objective.lower() == 'regression':\n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse_score = mean_squared_error(y_test, pred, squared=False)\n",
    "    rmse_score = round(rmse_score, 2)\n",
    "    print(f'RMSE: {rmse_score}')\n",
    "    score['RMSE'] = rmse_score\n",
    "    metrics.append(('RMSE', rmse_score))\n",
    "    \n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae_score = mean_absolute_error(y_test, pred)\n",
    "    mae_score = round(mae_score, 2)\n",
    "    print(f'MAE: {mae_score}')\n",
    "    metrics.append(('MAE', mae_score))\n",
    "    \n",
    "    # R-squared (R2)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    r2 = round(r2, 2)\n",
    "    print(f'R2 Score: {r2}')\n",
    "    metrics.append(('R2', r2))\n",
    "else:\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "    # Visualize the confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.ylabel('True Label', fontsize=13)\n",
    "    plt.xlabel('Predicted Label', fontsize=13)\n",
    "    plt.title('Confusion Matrix', fontsize=17)\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the plot as an HTML file\n",
    "    html_file_path = f'{folder_path}/confusion_matrix.html'\n",
    "    with open(html_file_path, 'w') as f:\n",
    "        f.write(mpld3.fig_to_html(plt.gcf()))\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_test, pred, average='weighted')  # Use appropriate average method if needed\n",
    "    f1 = round(f1, 2)\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    score['F1'] = f1\n",
    "    metrics.append(('F1', f1))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    accuracy = round(accuracy, 2)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    metrics.append(('Accuracy', accuracy))\n",
    "    \n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, pred, average='weighted')\n",
    "    precision = round(precision, 2)\n",
    "    print(\"Precision:\", precision)\n",
    "    metrics.append(('Precision', precision))\n",
    "    \n",
    "    # Calculate recall\n",
    "    recall = recall_score(y_test, pred, average='weighted')\n",
    "    recall = round(recall, 2)\n",
    "    print(\"Recall:\", recall)\n",
    "    metrics.append(('Recall', recall))\n",
    "                    \n",
    "# Create a DataFrame for all metrics\n",
    "df_metrics = pd.DataFrame(metrics, columns=['MetricName', 'Value'])\n",
    "\n",
    "# Save metrics to a CSV file\n",
    "csv_file_path = os.path.join(folder_path, 'model_metrics.csv')\n",
    "df_metrics.to_csv(csv_file_path, index=False)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dashbaord for Online Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_name = cube_name + '_' + table.split('.')[0] + '_auto_sklearn'\n",
    "dashboard_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if dashbaord exsists\n",
    "url = 'http://' + os.environ['API_GATEWAY_EXTERNAL_SERVICE_HOST'] + ':' + os.environ['API_GATEWAY_EXTERNAL_SERVICE_PORT']\n",
    "endpoint = f'/api/v1/dashboards?datasourceTitle={cube_name}'\n",
    "\n",
    "response = sisense_conn.call_api_custom('GET',url,endpoint, params=None, payload=None)\n",
    "response\n",
    "res = response.json()\n",
    "dashboard_exists = False\n",
    "dash_id = ''\n",
    "# Check if the dashboard already exists\n",
    "for dash in res:\n",
    "    if dash['title'] == dashboard_name:\n",
    "        dashboard_exists = True\n",
    "        dash_id = dash['oid']\n",
    "        print(f\"Dashboard '{dashboard_name}' - '{dash_id}' Already Exists\")\n",
    "        break\n",
    "\n",
    "# If the dashboard does not exist, create it\n",
    "if not dashboard_exists:\n",
    "    print(f'Creating Dashboard as {dashboard_name}')\n",
    "    payload = {\n",
    "        \"title\": dashboard_name,\n",
    "        \"datasource\": {\n",
    "            \"fullname\": f\"localhost/{cube_name}\",\n",
    "            \"id\": f\"localhost_{cube_name}\",\n",
    "            \"address\": \"LocalHost\",\n",
    "            \"database\": cube_name,\n",
    "            \"live\": False,\n",
    "            \"title\": cube_name\n",
    "        },\n",
    "        \"type\": \"dashboard\",\n",
    "        \"desc\": \"\",\n",
    "        \"filters\": [],\n",
    "        \"style\": {},\n",
    "        \"editing\": True\n",
    "    }\n",
    "\n",
    "    dash_endpoint = f'/api/dashboards/'\n",
    "    # response = requests.post(dash_endpoint, headers=source_head, data=json.dumps(payload))\n",
    "    response = sisense_conn.call_api_custom('POST',url,dash_endpoint, params=None, payload=payload)\n",
    "    res=response.json()\n",
    "    dash_id = res[0]['oid']\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Dashboard '{dashboard_name}' - '{dash_id}' created successfully\")\n",
    "    else:\n",
    "        print(f'Failed to create dashboard {dashboard_name}. Status code: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Widget Payload \n",
    "def generate_payload(features):\n",
    "    columns = []\n",
    "    num_columns = 3\n",
    "    items_per_column = len(features) // num_columns\n",
    "    extra_items = len(features) % num_columns\n",
    "    \n",
    "    feature_index = 0\n",
    "\n",
    "    for col in range(num_columns):\n",
    "        column = {\n",
    "            \"type\": \"Column\",\n",
    "            \"separator\": col == 0,  # Only the first column has separator set to True\n",
    "            \"spacing\": \"large\",\n",
    "            \"items\": []\n",
    "        }\n",
    "\n",
    "        for item in range(items_per_column + (1 if col < extra_items else 0)):\n",
    "            feature = features[feature_index]\n",
    "            item_dict = {\n",
    "                \"spacing\": \"large\",\n",
    "                \"type\": \"Input.Text\",\n",
    "                \"id\": f\"data.{feature}\",\n",
    "                \"placeholder\": feature,\n",
    "                \"defaultValue\": \"\",\n",
    "                \"isMultiline\": True,\n",
    "                \"rows\": \"2\",\n",
    "                \"borderRadius\": \"14px\",\n",
    "                \"borderStyle\": \"none\",\n",
    "                \"backgroundColor\": \"lightgrey\"\n",
    "            }\n",
    "            column[\"items\"].append(item_dict)\n",
    "            feature_index += 1\n",
    "\n",
    "        columns.append(column)\n",
    "\n",
    "    payload = {\n",
    "        \"columns\": columns\n",
    "    }\n",
    "\n",
    "    # return json.dumps(payload, indent=4)\n",
    "    return payload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if widget exists\n",
    "# widget_endpoint = f'{url}/api/v1/dashboards/{dash_id}/widgets'\n",
    "# response = requests.get(widget_endpoint, headers=source_head)\n",
    "widget_endpoint = f'/api/v1/dashboards/{dash_id}/widgets'\n",
    "response = sisense_conn.call_api_custom('GET',url,widget_endpoint, params=None, payload=None)\n",
    "res = response.json()\n",
    "widget_id = ''\n",
    "widget_exists = False\n",
    "\n",
    "# Check if the widget already exists\n",
    "for widget in res:\n",
    "    if widget['title'] == table.split('.')[0] + '_auto_sklearn_online_prediction':\n",
    "        widget_exists = True\n",
    "        widget_id= widget[\"oid\"]\n",
    "        print(f\"Widget {widget_id} 'Online-Prediction' in '{dashboard_name}' Already Exists\")\n",
    "        break\n",
    "\n",
    "# If the widget does not exist, create it\n",
    "if not widget_exists:\n",
    "    print(f'Creating Widget in {dashboard_name}')\n",
    "    payload = {\n",
    "    \"title\": table.split('.')[0] + '_auto_sklearn_online_prediction',\n",
    "    \"type\": \"BloX\",\n",
    "    \"subtype\": \"BloX\",\n",
    "    \"desc\": None,\n",
    "    \"source\": None,\n",
    "    \"datasource\": {\n",
    "        \"title\": cube_name,\n",
    "        \"fullname\": f'LocalHost/{cube_name}',\n",
    "        \"id\": f'LOCALHOST_{cube_name}',\n",
    "        \"address\": \"LocalHost\",\n",
    "        \"database\": cube_name\n",
    "    },\n",
    "    \"selection\": None,\n",
    "    \"metadata\": {\n",
    "        \"ignore\": {\n",
    "            \"dimensions\": [],\n",
    "            \"ids\": [],\n",
    "            \"all\": False\n",
    "        },\n",
    "        \"panels\": [\n",
    "            {\n",
    "                \"name\": \"Items\",\n",
    "                \"items\": []\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Values\",\n",
    "                \"items\": []\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"filters\",\n",
    "                \"items\": []\n",
    "            }\n",
    "        ],\n",
    "        \"usedFormulasMapping\": {}\n",
    "    },\n",
    "    \"style\": {\n",
    "        \"currentCard\": {\n",
    "            \"style\": \"\",\n",
    "            \"script\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"showCarousel\": True,\n",
    "            \"backgroundImage\": \"\",\n",
    "            \"body\": [\n",
    "                {\n",
    "                    \"type\": \"Container\",\n",
    "                    \"items\": [\n",
    "                        {\n",
    "                            \"type\": \"TextBlock\",\n",
    "                            \"text\": \"Sisense AutoML\",\n",
    "                            \"size\": \"extraLarge\",\n",
    "                            \"color\": \"yellow\",\n",
    "                            \"weight\": \"bold\",\n",
    "                            \"horizontalAlignment\": \"center\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"ColumnSet\",\n",
    "                            \"spacing\": \"extraLarge\",\n",
    "                            \"columns\": []\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"Container\",\n",
    "                    \"separator\": False,\n",
    "                    \"id\": \"outputContainer\",\n",
    "                    \"size\": \"Large\",\n",
    "                    \"items\": [\n",
    "                        {\n",
    "                            \"type\": \"ActionSet\",\n",
    "                            \"actions\": [\n",
    "                                {\n",
    "                                    \"type\": \"new_online_prediction\",\n",
    "                                    \"title\": \"Predict\",\n",
    "                                    \"data\": {\n",
    "                                        \"question\": \"\",\n",
    "                                        \"table\": \"\"\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            \"spacing\": \"extraLarge\",\n",
    "                            \"type\": \"TextBlock\",\n",
    "                            \"text\": \"Output \",\n",
    "                            \"color\": \"green\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"currentConfig\": {\n",
    "            \"fontFamily\": \"Open Sans\",\n",
    "            \"fontSizes\": {\n",
    "                \"default\": 16,\n",
    "                \"small\": 12,\n",
    "                \"medium\": 22,\n",
    "                \"large\": 32,\n",
    "                \"extraLarge\": 50\n",
    "            },\n",
    "            \"fontWeights\": {\n",
    "                \"default\": 500,\n",
    "                \"light\": 100,\n",
    "                \"bold\": 900\n",
    "            },\n",
    "            \"containerStyles\": {\n",
    "                \"default\": {\n",
    "                    \"backgroundColor\": \"black\",\n",
    "                    \"foregroundColors\": {\n",
    "                        \"default\": {\n",
    "                            \"normal\": \"#3A4356\"\n",
    "                        },\n",
    "                        \"white\": {\n",
    "                            \"normal\": \"#ffffff\"\n",
    "                        },\n",
    "                        \"grey\": {\n",
    "                            \"normal\": \"#dcdcdc\"\n",
    "                        },\n",
    "                        \"orange\": {\n",
    "                            \"normal\": \"#f2B900\"\n",
    "                        },\n",
    "                        \"yellow\": {\n",
    "                            \"normal\": \"#ffcb05\"\n",
    "                        },\n",
    "                        \"black\": {\n",
    "                            \"normal\": \"#000000\"\n",
    "                        },\n",
    "                        \"lightGreen\": {\n",
    "                            \"normal\": \"#93c0c0\"\n",
    "                        },\n",
    "                        \"green\": {\n",
    "                            \"normal\": \"#54a254\"\n",
    "                        },\n",
    "                        \"red\": {\n",
    "                            \"normal\": \"#dd1111\"\n",
    "                        },\n",
    "                        \"accent\": {\n",
    "                            \"normal\": \"#2E89FC\"\n",
    "                        },\n",
    "                        \"good\": {\n",
    "                            \"normal\": \"#54a254\"\n",
    "                        },\n",
    "                        \"warning\": {\n",
    "                            \"normal\": \"#e69500\"\n",
    "                        },\n",
    "                        \"attention\": {\n",
    "                            \"normal\": \"#cc3300\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"imageSizes\": {\n",
    "                \"default\": 40,\n",
    "                \"small\": 40,\n",
    "                \"medium\": 80,\n",
    "                \"large\": 160\n",
    "            },\n",
    "            \"imageSet\": {\n",
    "                \"imageSize\": \"medium\",\n",
    "                \"maxImageHeight\": 100\n",
    "            },\n",
    "            \"actions\": {\n",
    "                \"color\": \"\",\n",
    "                \"backgroundColor\": \"red\",\n",
    "                \"maxActions\": 5,\n",
    "                \"spacing\": \"extraLarge\",\n",
    "                \"buttonSpacing\": 20,\n",
    "                \"actionsOrientation\": \"horizontal\",\n",
    "                \"actionAlignment\": \"center\",\n",
    "                \"showCard\": {\n",
    "                    \"actionMode\": \"inline\",\n",
    "                    \"inlineTopMargin\": 16,\n",
    "                    \"style\": \"default\"\n",
    "                }\n",
    "            },\n",
    "            \"spacing\": {\n",
    "                \"default\": 5,\n",
    "                \"small\": 5,\n",
    "                \"medium\": 10,\n",
    "                \"large\": 20,\n",
    "                \"extraLarge\": 40,\n",
    "                \"padding\": 20\n",
    "            },\n",
    "            \"separator\": {\n",
    "                \"lineThickness\": 1,\n",
    "                \"lineColor\": \"#eeeeee\"\n",
    "            },\n",
    "            \"factSet\": {\n",
    "                \"title\": {\n",
    "                    \"size\": \"default\",\n",
    "                    \"color\": \"default\",\n",
    "                    \"weight\": \"bold\",\n",
    "                    \"warp\": True\n",
    "                },\n",
    "                \"value\": {\n",
    "                    \"size\": \"default\",\n",
    "                    \"color\": \"default\",\n",
    "                    \"weight\": \"default\",\n",
    "                    \"warp\": True\n",
    "                },\n",
    "                \"spacing\": 20\n",
    "            },\n",
    "            \"supportsInteractivity\": True,\n",
    "            \"imageBaseUrl\": \"\",\n",
    "            \"height\": 743\n",
    "        },\n",
    "        \"currentCardName\": \"Multiple Indicator\",\n",
    "        \"narration\": {\n",
    "            \"enabled\": False,\n",
    "            \"display\": \"above\",\n",
    "            \"format\": \"bullets\",\n",
    "            \"verbosity\": \"medium\",\n",
    "            \"up_sentiment\": \"good\",\n",
    "            \"aggregation\": \"sum\",\n",
    "            \"labels\": []\n",
    "        }\n",
    "    }\n",
    "}\n",
    "    payload_columns = generate_payload(widget_features)\n",
    "    payload['style']['currentCard']['body'][0]['items'][1]['columns'] = payload_columns['columns']\n",
    "    # dash_endpoint = f'{url}/api/v1/dashboards/{dash_id}/widgets'\n",
    "    response = sisense_conn.call_api_custom('POST',url,widget_endpoint, params=None, payload=payload)\n",
    "    # response = requests.post(widget_endpoint, headers=source_head, data=json.dumps(payload))\n",
    "    widget_id = response.json()[\"oid\"]\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "        print(f\"Widget '{widget_id}' - '_auto_sklearn_online_prediction' in '{dashboard_name}' created successfully\")\n",
    "    else:\n",
    "        print(f'Failed to create Widget in \"{dashboard_name}\". Status code: {response.status_code}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create result dataframe for model name and accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metric name and value from score\n",
    "key, value = next(iter(score.items()))\n",
    "df = pd.DataFrame()\n",
    "df['model_name'] = [model]\n",
    "df['metric_name'] = [key]\n",
    "df['score'] = [round(value, 2)]\n",
    "path = folder_path + '/'\n",
    "df['path'] = [path]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model information in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = f\"/opt/sisense/storage/notebooks/custom_code_notebooks/notebooks/automl/models/\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "new_df = df.copy()\n",
    "new_df['provider'] = 'Auto-Sklearn'\n",
    "new_df['created_date'] = datetime.now()\n",
    "new_df['dash_id'] = dash_id\n",
    "new_df['widget_id'] = widget_id\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_file_path = f\"/opt/sisense/storage/notebooks/custom_code_notebooks/notebooks/automl/models/models.csv\"\n",
    "# Check if models.csv file exists\n",
    "if not os.path.exists(models_file_path):\n",
    "    # If it does not exist, create an empty DataFrame and save it as models.csv\n",
    "    empty_df = pd.DataFrame(columns=new_df.columns)\n",
    "    empty_df.to_csv(models_file_path, index=False)\n",
    "    print('empty')\n",
    "old_df = pd.read_csv(models_file_path)\n",
    "if old_df.empty:\n",
    "    combined_df = new_df\n",
    "else:\n",
    "    combined_df = pd.concat([old_df, new_df], axis=0)\n",
    "\n",
    "combined_df.to_csv(models_file_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model information in Custom Code Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
