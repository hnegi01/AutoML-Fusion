{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "# The variables below have to be included in the test cell in order to query the cube.\n",
    "from init_sisense import sisense_conn\n",
    "cube_name = \"bank_churn\"\n",
    "additional_parameters = sisense_conn.load_additional_parameters(cube_name, table_name=\"bank_churn_train_sagemaker_ml533\")\n",
    "sisense_conn.set_parameters(cube_name=cube_name, additional_parameters=additional_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Sagemaker AutoPilot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install boto3 sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime, sleep , time\n",
    "import os\n",
    "import json\n",
    "import tarfile\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load input parameters from custom code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = sisense_conn.add_param[\"Dataset\"][\"table\"]\n",
    "target_column = sisense_conn.add_param[\"Target Column\"][\"column\"]\n",
    "drop_column = sisense_conn.add_param[\"Drop Feature\"]\n",
    "aws_access_key_path = sisense_conn.add_param[\"aws_access_key_path\"]\n",
    "aws_secret_access_path = sisense_conn.add_param[\"aws_secret_access_path\"]\n",
    "region_name = sisense_conn.add_param[\"region_name\"]\n",
    "S3_bucket_name = sisense_conn.add_param[\"S3_bucket_name\"]\n",
    "aws_arn_role = sisense_conn.add_param[\"aws_arn_role\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from Elasticube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Sql Statement\n",
    "logical_sql1 = (f'SELECT * from \"{table}\"')\n",
    "print(\"SQL Statement:\\n\" + logical_sql1)\n",
    "# Execute the SQL Statement\n",
    "logical_sql_res1 = sisense_conn.get_logical_sql(query=logical_sql1, \n",
    "                                               cube_name=cube_name,  # passed to notebook from build / Test Cell\n",
    "                                               count=None)  # limit the rows fetched\n",
    "# check for errors in logical sql execution \n",
    "# if \"error\" in logical_sql_res1:\n",
    "#     raise err.CustomCodeException(*err.ERROR_IN_LOGICAL_SQL, description=logical_sql_res1.get(\"details\"))\n",
    "column_name = logical_sql_res1['headers']\n",
    "values = logical_sql_res1['values']\n",
    "# Get Data\n",
    "df = pd.DataFrame(values, columns = column_name)\n",
    "if drop_column != '0':\n",
    "    # Split the drop_column string into a list of column names\n",
    "    columns_to_drop = drop_column.split(',')\n",
    "    # Drop the specified columns\n",
    "    df = df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '.' in table:\n",
    "    dataset = table.split('.')[0]\n",
    "else:\n",
    "    dataset = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = df.columns.tolist()\n",
    "features = [col for col in all_columns if col != target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create list of features for Widget\n",
    "widget_features = df.columns.tolist()\n",
    "\n",
    "# Remove the target column from the list\n",
    "if target_column in widget_features:\n",
    "    widget_features.remove(target_column)\n",
    "widget_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directory in Sisense to store files and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_timestamp = datetime.now()\n",
    "current_timestamp = current_timestamp.strftime('%Y%m%d%H%M%S')\n",
    "folder_path = f\"/opt/sisense/storage/notebooks/custom_code_notebooks/notebooks/sagemaker/{table.split('.')[0]}/{current_timestamp}\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Feature list locally\n",
    "json_file_path = f'{folder_path}/features.json'\n",
    "\n",
    "# Open the file in write mode and use json.dump() to write the list\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(features, json_file, indent=4) \n",
    "\n",
    "print(f\"Features list saved to {json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use sagemkaer autopilot library we need to put the data on S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get AWS Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the access key from file\n",
    "with open(aws_access_key_path, 'r') as f:\n",
    "    aws_access_key_id = f.read().strip()\n",
    "\n",
    "with open(aws_secret_access_path, 'r') as f:\n",
    "    aws_secret_access_key = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key, region_name=region_name)\n",
    "\n",
    "# Create the S3 bucket\n",
    "s3.create_bucket(Bucket=S3_bucket_name)\n",
    "\n",
    "# Convert the DataFrame to a CSV file in memory\n",
    "csv_buffer = io.StringIO()\n",
    "df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# Specify the desired S3 key (object name) for the CSV file\n",
    "s3_key = f\"{dataset}/input-data.csv\" # Replace with the desired S3 key\n",
    "\n",
    "# Upload the CSV file to the S3 bucket\n",
    "s3.put_object(Bucket=S3_bucket_name, Key=s3_key, Body=csv_buffer.getvalue())\n",
    "\n",
    "print(f\"Uploaded the Csv to s3://{S3_bucket_name}/{dataset}/{s3_key}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up AWS Configuration locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(aws_access_key_id=aws_access_key_id,\n",
    "                            aws_secret_access_key=aws_secret_access_key,\n",
    "                            region_name=region_name)\n",
    "region = boto3.Session().region_name\n",
    "session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the SageMaker client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autopilot = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters for the AutoML job\n",
    "### Customize your paramter using aws [documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker/client/create_auto_ml_job_v2.html)\n",
    "##### For MODE:AUTO If your dataset is larger than 100 MB, Autopilot chooses HPO.\n",
    "\n",
    "#### ENSEMBLING vs HYPERPARAMETER_TUNING\n",
    "##### Data Characteristics: For large or complex datasets, AUTO mode might lean towards ENSEMBLING because it can leverage diverse algorithms to capture various data patterns, potentially improving overall model performance.\n",
    "##### Performance vs. Time: If the primary goal is quick model training with reasonable performance, HYPERPARAMETER_TUNING might be preferred for smaller datasets. Conversely, for larger datasets where computation resources allow, ENSEMBLING can provide robust models at the expense of longer training times.\n",
    "##### Resource Allocation: The choice between these modes can also impact the types of AWS resources used, such as processing power and storage. Ensembling might require more resources to handle multiple models simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ml_job_input_data_config = [\n",
    "    {\n",
    "        'ChannelType': 'training', # training or validation\n",
    "        'ContentType': 'text/csv;header=present',\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': f's3://{S3_bucket_name}/{s3_key}'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "output_data_config = {\n",
    "    'S3OutputPath': f's3://{S3_bucket_name}/{dataset}/autopilot-output/'\n",
    "}\n",
    "\n",
    "## If using Mode:Auto no need for CandidateGenerationConfig -Sagemkaer will choose ENSEMBLING or HYPERPARAMETER based on datasize\n",
    "auto_ml_problem_type_config = {\n",
    "    'TabularJobConfig': {\n",
    "        # 'CandidateGenerationConfig': {\n",
    "        #     'AlgorithmsConfig': [\n",
    "        #     ]\n",
    "        # },\n",
    "        'CompletionCriteria': {\n",
    "            'MaxCandidates': 10, #10\n",
    "            'MaxRuntimePerTrainingJobInSeconds': 3600, #1200\n",
    "            'MaxAutoMLJobRuntimeInSeconds': 9000 #9000\n",
    "        },\n",
    "         'Mode': 'AUTO',\n",
    "        # 'ProblemType': 'BinaryClassification',\n",
    "        'TargetAttributeName': target_column\n",
    "#         'SampleWeightAttributeName': 'string'\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "## If using Mode:Ensembling\n",
    "# auto_ml_problem_type_config = {\n",
    "#     'TabularJobConfig': {\n",
    "#         'CandidateGenerationConfig': {\n",
    "#             'AlgorithmsConfig': [\n",
    "#                 {\n",
    "#                     'AutoMLAlgorithms': [\n",
    "#                         'catboost',\n",
    "#                         'extra-trees',\n",
    "#                         'fastai',\n",
    "#                         'lightgbm',\n",
    "#                         'linear-learner',\n",
    "#                         'nn-torch',\n",
    "#                         'randomforest',\n",
    "#                         'xgboost'\n",
    "#                     ]\n",
    "#                 }\n",
    "#             ]\n",
    "#         },\n",
    "#         'CompletionCriteria': {\n",
    "#             'MaxCandidates': 10,\n",
    "#             'MaxRuntimePerTrainingJobInSeconds': 1200,\n",
    "#             'MaxAutoMLJobRuntimeInSeconds': 9000\n",
    "#         },\n",
    "#         'Mode': 'ENSEMBLING',\n",
    "#         'TargetAttributeName': target_column,\n",
    "#         'SampleWeightAttributeName': 'SampleWeight' ## SampleWeight is a custom column in your datatset. Ex have values like 0 for class '0' if this class has more records and value like 4 for class '1' which has underrepresented row.\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# If using HYPERPARAMETER_TUNING\n",
    "# auto_ml_problem_type_config = {\n",
    "#     'TabularJobConfig': {\n",
    "#         'CandidateGenerationConfig': {\n",
    "#             'AlgorithmsConfig': [\n",
    "#                 {\n",
    "#                     'AutoMLAlgorithms': [\n",
    "#                         'linear-learner',\n",
    "#                         'mlp',\n",
    "#                         'xgboost'\n",
    "#                     ]\n",
    "#                 }\n",
    "#             ]\n",
    "#         },\n",
    "#         'CompletionCriteria': {\n",
    "#             'MaxCandidates': 10,\n",
    "#             'MaxRuntimePerTrainingJobInSeconds': 1200,\n",
    "#             'MaxAutoMLJobRuntimeInSeconds': 9000\n",
    "#         },\n",
    "#         'Mode': 'HYPERPARAMETER_TUNING',\n",
    "#         'TargetAttributeName': target_column\n",
    "#     }\n",
    "# }\n",
    "\n",
    "\n",
    "role_arn = aws_arn_role\n",
    "\n",
    "# Regression: MSE | Binary classification: F1 | Multiclass classification: Accuracy.\n",
    "# auto_ml_job_objective = { \n",
    "#     'MetricName': 'Accuracy'\n",
    "# }\n",
    "\n",
    "\n",
    "# model_deploy_config = {\n",
    "#     'AutoGenerateEndpointName': False,\n",
    "#     'EndpointName': 'string'\n",
    "# }\n",
    "\n",
    "data_split_config = {\n",
    "    'ValidationFraction': 0.2  # Change to your desired value\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the create_auto_ml_job_v2 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestamp_suffix = strftime(\"%Y%m%d%H%M\", gmtime())\n",
    "auto_ml_job_name = \"sisense-autopilot\" + timestamp_suffix\n",
    "print(\"AutoMLJobName: \" + auto_ml_job_name)\n",
    "\n",
    "autopilot.create_auto_ml_job_v2(\n",
    "    AutoMLJobName=auto_ml_job_name,\n",
    "    AutoMLJobInputDataConfig=auto_ml_job_input_data_config,\n",
    "    OutputDataConfig=output_data_config,\n",
    "    AutoMLProblemTypeConfig=auto_ml_problem_type_config,\n",
    "    RoleArn=role_arn,\n",
    "#     Tags=tags,\n",
    "#     SecurityConfig=security_config,\n",
    "#     AutoMLJobObjective=auto_ml_job_objective,\n",
    "#     ModelDeployConfig=model_deploy_config,\n",
    "    DataSplitConfig=data_split_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"JobStatus - Secondary Status\")\n",
    "print(\"------------------------------\")\n",
    "\n",
    "\n",
    "describe_response = autopilot.describe_auto_ml_job_v2(AutoMLJobName=auto_ml_job_name)\n",
    "print(describe_response[\"AutoMLJobStatus\"] + \" - \" + describe_response[\"AutoMLJobSecondaryStatus\"])\n",
    "job_run_status = describe_response[\"AutoMLJobStatus\"]\n",
    "\n",
    "while job_run_status not in (\"Failed\", \"Completed\", \"Stopped\"):\n",
    "    describe_response = autopilot.describe_auto_ml_job_v2(AutoMLJobName=auto_ml_job_name)\n",
    "    job_run_status = describe_response[\"AutoMLJobStatus\"]\n",
    "\n",
    "    print(\n",
    "        describe_response[\"AutoMLJobStatus\"] + \" - \" + describe_response[\"AutoMLJobSecondaryStatus\"]\n",
    "    )\n",
    "    sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc = autopilot.describe_auto_ml_job_v2(AutoMLJobName=auto_ml_job_name)\n",
    "job_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_desc[\"BestCandidate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can use the describe_auto_ml_job API to look up the best candidate selected by the SageMaker Autopilot job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_candidate = job_desc[\"BestCandidate\"]\n",
    "best_candidate_name = best_candidate[\"CandidateName\"]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"CandidateName: \" + best_candidate_name)\n",
    "print(\n",
    "    \"FinalAutoMLJobObjectiveMetricName: \"\n",
    "    + best_candidate[\"FinalAutoMLJobObjectiveMetric\"][\"MetricName\"]\n",
    ")\n",
    "print(\n",
    "    \"FinalAutoMLJobObjectiveMetricValue: \"\n",
    "    + str(best_candidate[\"FinalAutoMLJobObjectiveMetric\"][\"Value\"])\n",
    ")\n",
    "print(\"\\nBest candidate details:: \" + str(best_candidate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To explore the performance of other algorithms that Autopilot explored, you can enumerate them via list_candidates_for_auto_ml_job API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autopilot_dict = autopilot.list_candidates_for_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "\n",
    "for item in autopilot_dict[\"Candidates\"]:\n",
    "    print(item[\"CandidateName\"], item[\"FinalAutoMLJobObjectiveMetric\"])\n",
    "    print(item[\"InferenceContainers\"][0][\"Image\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autopilot also automatically generates a feature importance report store them locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_candidate[\"CandidateProperties\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_s3_path(s3_path):\n",
    "    # Handle the case where the s3_path is an empty string or just spaces\n",
    "    if not s3_path.strip():\n",
    "        return None, None  # Return None for both bucket and key if the path is empty\n",
    "\n",
    "    path_parts = s3_path.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = path_parts.pop(0)\n",
    "    key = \"/\".join(path_parts)\n",
    "    return bucket, key\n",
    "\n",
    "# Safely access 'CandidateArtifactLocations' and 'Explainability'\n",
    "candidate_artifact_locations = best_candidate.get(\"CandidateProperties\", {}).get(\"CandidateArtifactLocations\", {})\n",
    "\n",
    "# Check if 'Explainability' exists\n",
    "explainability_prefix = candidate_artifact_locations.get(\"Explainability\")\n",
    "\n",
    "# Proceed only if explainability_prefix is valid and not empty\n",
    "if explainability_prefix and explainability_prefix.strip():\n",
    "    s3_bucket, explainability_dir = split_s3_path(explainability_prefix)\n",
    "\n",
    "    # Proceed only if valid S3 bucket and key were returned\n",
    "    if s3_bucket and explainability_dir:\n",
    "        session.download_data(path=folder_path, bucket=s3_bucket, key_prefix=explainability_dir)\n",
    "    else:\n",
    "        print(\"Explainability prefix is invalid or empty.\")\n",
    "else:\n",
    "    print(\"Explainability prefix is not provided or missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import IFrame\n",
    "\n",
    "# # Display HTML report\n",
    "# IFrame(src=\"report.html\", width=700, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# you will need transform job for data processing/feature engineering\n",
    "# and tuning job for model tuning/fitting\n",
    "transform_job = \"\"\n",
    "tuning_job = \"\"\n",
    "processing_job = \"\"\n",
    "training_job = \"\"\n",
    "for index in range(len(best_candidate[\"CandidateSteps\"])):\n",
    "    if (\n",
    "        best_candidate[\"CandidateSteps\"][index][\"CandidateStepType\"]\n",
    "        == \"AWS::SageMaker::TransformJob\"\n",
    "    ):\n",
    "        transform_job = best_candidate[\"CandidateSteps\"][index][\"CandidateStepName\"]\n",
    "    if (\n",
    "        best_candidate[\"CandidateSteps\"][index][\"CandidateStepType\"]\n",
    "        == \"AWS::SageMaker::TuningJob\"\n",
    "    ):\n",
    "        tuning_job = best_candidate[\"CandidateSteps\"][index][\"CandidateStepName\"]\n",
    "    if (\n",
    "        best_candidate[\"CandidateSteps\"][index][\"CandidateStepType\"]\n",
    "        == \"AWS::SageMaker::ProcessingJob\"\n",
    "    ):\n",
    "        processing_job = best_candidate[\"CandidateSteps\"][index][\"CandidateStepName\"]\n",
    "    if (\n",
    "        best_candidate[\"CandidateSteps\"][index][\"CandidateStepType\"]\n",
    "        == \"AWS::SageMaker::TrainingJob\"\n",
    "    ):\n",
    "        training_job = best_candidate[\"CandidateSteps\"][index][\"CandidateStepName\"]\n",
    "\n",
    "print(f\"transform_job:{transform_job}, tuning_job:{tuning_job}, training_job:{training_job}, processing_job:{processing_job}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can describe the job to see the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a list of jobs\n",
    "job_list = [\n",
    "    ('transform_job', transform_job),\n",
    "    ('tuning_job', tuning_job),\n",
    "    ('processing_job', processing_job),\n",
    "    ('training_job', training_job)\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store responses\n",
    "response = []\n",
    "\n",
    "# Iterate over the job list and retrieve job descriptions\n",
    "for job_type, job_name in job_list:\n",
    "    if job_name:  # Check if the job name is not empty\n",
    "        if job_type == 'transform_job':\n",
    "            response.append(autopilot.describe_transform_job(TransformJobName=job_name))\n",
    "        elif job_type == 'tuning_job':\n",
    "            response.append(autopilot.describe_tuning_job(TuningJobName=job_name))\n",
    "        elif job_type == 'training_job':\n",
    "            response.append(autopilot.describe_training_job(TrainingJobName=job_name))\n",
    "        elif job_type == 'processing_job':\n",
    "            response.append(autopilot.describe_processing_job(ProcessingJobName=job_name))\n",
    "\n",
    "# Access the first response\n",
    "first_response = response[0] if response else None\n",
    "\n",
    "# Print the responses\n",
    "for i, res in enumerate(response, start=1):\n",
    "    print(f\"Response {i}: {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### OLD LOGIC\n",
    "# job_list = [transform_job,tuning_job,processing_job,training_job]\n",
    "# response = []\n",
    "# for job in job_list:\n",
    "#     if job != '':\n",
    "#         if job == 'transform_job':\n",
    "#             response.append(autopilot.describe_transform_job(TransformJobName=job))\n",
    "#         elif job == 'tuning_job':\n",
    "#             response.append(autopilot.describe_tuning_job(TuningJobName=job))\n",
    "#         elif job == 'training_job':\n",
    "#             response.append(autopilot.describe_training_job(TrainingJobName=job))\n",
    "#         else:\n",
    "#             response.append(autopilot.describe_processing_job(ProcessingJobName=job))\n",
    "            \n",
    "# response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ml_job_name, best_candidate_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_candidate = job_desc[\"BestCandidate\"]\n",
    "# best_candidate[\"InferenceContainers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_candidate[\"InferenceContainers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestamp_suffix = strftime(\"%d\", gmtime())\n",
    "dataset = dataset.replace('_','-')\n",
    "model_name = 'sisense-autopilot-' + dataset + timestamp_suffix + \"-model\"\n",
    "model = autopilot.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=best_candidate[\"InferenceContainers\"],\n",
    "    ExecutionRoleArn=aws_arn_role\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def describe_autopilot_model(response):\n",
    "    model_locations = {}  # Dictionary to store model locations for each role\n",
    "    final_model_name = None\n",
    "    containers = response['Containers']\n",
    "\n",
    "    # Check if it's an Ensemble model by looking for 'MODEL_NAME'\n",
    "    for container in containers:\n",
    "        environment = container['Environment']\n",
    "        if 'MODEL_NAME' in environment:\n",
    "            model_location = container['ModelDataUrl']\n",
    "            final_model_name = environment['MODEL_NAME']\n",
    "            print(f\"Ensemble Model Detected.\")\n",
    "            print(f\"Final Ensemble Model Name: {final_model_name}\")\n",
    "            print(f\"Model Location: {model_location}\\n\")\n",
    "\n",
    "            # Store the model location for Ensemble\n",
    "            model_locations['ensemble'] = model_location\n",
    "            return model_locations, final_model_name\n",
    "\n",
    "    # HPO Case: Dynamically determine regression vs classification by number of containers\n",
    "    num_containers = len(containers)\n",
    "\n",
    "    if num_containers == 2:\n",
    "        # HPO for Regression (2 containers: Pre-processing and Inference)\n",
    "        container_labels = [\n",
    "            \"Feature Engineering Pre-processing\",\n",
    "            \"Trained Model (Regression)\"\n",
    "        ]\n",
    "    elif num_containers == 3:\n",
    "        # HPO for Classification (3 containers: Pre-processing, Inference, Post-processing)\n",
    "        container_labels = [\n",
    "            \"Feature Engineering Pre-processing\",\n",
    "            \"Trained Model (Classification)\",\n",
    "            \"Post-processing\"\n",
    "        ]\n",
    "    else:\n",
    "        print(f\"Unexpected number of containers: {num_containers}\")\n",
    "        return model_locations, final_model_name\n",
    "\n",
    "    # Final model name for HPO\n",
    "    final_model_name = response['ModelName']\n",
    "    print(f\"HPO Model Detected.\\nFinal HPO Model Name: {final_model_name}\")\n",
    "    \n",
    "    # Iterate over HPO containers and collect model locations\n",
    "    for i, container in enumerate(containers):\n",
    "        model_location = container['ModelDataUrl']\n",
    "        if i < len(container_labels):  # Ensure we stay within label bounds\n",
    "            print(f\"{container_labels[i]} Container\")\n",
    "            print(f\"Model Location: {model_location}\\n\")\n",
    "            \n",
    "            # Store model location by its role\n",
    "            role = container_labels[i].replace(\" \", \"_\").lower()  # Normalize the label as the key\n",
    "            model_locations[role] = model_location\n",
    "\n",
    "    return model_locations, final_model_name  # Return both model locations and final model name\n",
    "\n",
    "# Example usage:\n",
    "response = autopilot.describe_model(ModelName=model_name)\n",
    "model_locations, final_model_name = describe_autopilot_model(response)\n",
    "print(f\"Final Model Name: {final_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_name,model_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Trained Models from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Extract the bucket name and key from the S3 path\n",
    "# bucket_name, s3_key = model_location.replace('s3://', '').split('/', 1)\n",
    "# print(f\"Bucket: {bucket_name}, Key: {s3_key}\")\n",
    "\n",
    "# # Specify the local file path to save the downloaded tar file\n",
    "# local_tar_file_path = os.path.join(folder_path, os.path.basename(s3_key))\n",
    "# print(f\"Local tar file path: {local_tar_file_path}\")\n",
    "\n",
    "# # Download the model artifacts from Amazon S3\n",
    "# s3 = boto3.resource('s3')\n",
    "# s3.Bucket(bucket_name).download_file(s3_key, local_tar_file_path)\n",
    "# print(\"Downloaded the model tar file from S3.\")\n",
    "\n",
    "# # Untar the downloaded tar file\n",
    "# with tarfile.open(local_tar_file_path, 'r:gz') as tar:\n",
    "#     # List the contents of the tar file\n",
    "#     tar_members = tar.getmembers()\n",
    "\n",
    "#     # Debug: Print all member names\n",
    "#     print(\"Contents of the tar file:\")\n",
    "#     for member in tar_members:\n",
    "#         print(f\" - {member.name}\")\n",
    "\n",
    "#     # Check if a top-level directory named 'models' exists\n",
    "#     models_folder_exists = any(member.name.startswith('./models/') and member.isdir() for member in tar_members)\n",
    "\n",
    "#     if models_folder_exists:\n",
    "#         print(\"Found 'models/' directory in the tar file. Extracting as is.\")\n",
    "#         # Extract directly to folder_path since 'models' folder is already present\n",
    "#         tar.extractall(path=folder_path)\n",
    "#     else:\n",
    "#         print(\"No 'models/' directory found. Creating 'model' folder and extracting contents.\")\n",
    "#         # Create a 'model' directory only if 'models' folder is not present in the tar\n",
    "#         model_path = os.path.join(folder_path, 'model')\n",
    "#         os.makedirs(model_path, exist_ok=True)\n",
    "#         for member in tar_members:\n",
    "#             # Strip leading directories to ensure extraction directly into model_path\n",
    "#             member.name = os.path.basename(member.name)\n",
    "#             tar.extract(member, path=model_path)\n",
    "\n",
    "# # Remove the tar file after extraction (optional)\n",
    "# os.remove(local_tar_file_path)\n",
    "# print(\"Removed the tar file after extraction.\")\n",
    "\n",
    "# print(\"Model files extracted successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import tarfile\n",
    "\n",
    "def download_and_extract_model(model_location, folder_path, role, final_model_name=None, is_trained_model=False):\n",
    "    final_model_name = final_model_name.replace('-', '_')\n",
    "    # Ensure the base folder path exists\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Create a parent 'model' directory\n",
    "    model_base_path = os.path.join(folder_path, 'model')\n",
    "    os.makedirs(model_base_path, exist_ok=True)\n",
    "\n",
    "    # If this is the trained model, use final_model_name but place it inside the 'model' folder\n",
    "    if is_trained_model and final_model_name:\n",
    "        model_role_path = os.path.join(model_base_path, final_model_name)\n",
    "    else:\n",
    "        # Create a subdirectory within 'model' for each specific role\n",
    "        model_role_path = os.path.join(model_base_path, role.replace(\" \", \"_\").replace(\"-\", \"_\").lower())\n",
    "\n",
    "    # Extract the bucket name and key from the S3 path\n",
    "    bucket_name, s3_key = model_location.replace('s3://', '').split('/', 1)\n",
    "    print(f\"Bucket: {bucket_name}, Key: {s3_key}\")\n",
    "\n",
    "    # Specify the local file path to save the downloaded tar file\n",
    "    local_tar_file_path = os.path.join(folder_path, f\"{role.replace(' ', '_').replace('-', '_').lower()}_model.tar.gz\")\n",
    "    print(f\"Local tar file path: {local_tar_file_path}\")\n",
    "\n",
    "    # Download the model artifacts from Amazon S3\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.Bucket(bucket_name).download_file(s3_key, local_tar_file_path)\n",
    "    print(f\"Downloaded the {role} model tar file from S3.\")\n",
    "\n",
    "    # Untar the downloaded tar file\n",
    "    with tarfile.open(local_tar_file_path, 'r:gz') as tar:\n",
    "        # List the contents of the tar file\n",
    "        tar_members = tar.getmembers()\n",
    "\n",
    "        # Debug: Print all member names\n",
    "        print(\"Contents of the tar file:\")\n",
    "        for member in tar_members:\n",
    "            print(f\" - {member.name}\")\n",
    "\n",
    "        # Check if a top-level directory named 'models' exists in the tar file\n",
    "        models_folder_exists = any(member.name.startswith('models/') and member.isdir() for member in tar_members)\n",
    "\n",
    "        if models_folder_exists:\n",
    "            print(\"Found 'models/' directory in the tar file. Extracting directly to folder_path.\")\n",
    "            # Extract directly to folder_path since 'models' folder is already present\n",
    "            tar.extractall(path=folder_path)\n",
    "        else:\n",
    "            print(f\"No 'models/' directory found. Creating '{model_role_path}' folder and extracting contents.\")\n",
    "            # Ensure the model role folder exists\n",
    "            os.makedirs(model_role_path, exist_ok=True)\n",
    "\n",
    "            # Extract contents into the role-specific folder under 'model'\n",
    "            for member in tar_members:\n",
    "                # Strip leading directories to ensure extraction directly into model_role_path\n",
    "                member.name = os.path.basename(member.name)\n",
    "                tar.extract(member, path=model_role_path)\n",
    "\n",
    "    # Remove the tar file after extraction (optional)\n",
    "    os.remove(local_tar_file_path)\n",
    "    print(f\"Removed the tar file after extraction for {role}.\")\n",
    "\n",
    "    print(f\"{role.capitalize().replace('_', ' ')} model files extracted successfully.\")\n",
    "\n",
    "# Download and extract each model with a unique name based on its role\n",
    "for i, (role, model_location) in enumerate(model_locations.items()):\n",
    "    # If this is the second tar file (the trained model), save it using final_model_name\n",
    "    is_trained_model = (i == 1)  # Assuming the second item is the trained model\n",
    "    download_and_extract_model(model_location, folder_path, role, final_model_name=final_model_name, is_trained_model=is_trained_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## OLD LOGIC\n",
    "# directory_name = final_model_name.replace('-', '_')\n",
    "\n",
    "\n",
    "# # Check if folder_path exists\n",
    "# if os.path.exists(folder_path):\n",
    "#     # Variable to store the full path if directory is found\n",
    "#     found_path = None\n",
    "    \n",
    "#     # Walk through all subdirectories under folder_path\n",
    "#     for root, dirs, files in os.walk(folder_path):\n",
    "#         # Check if the target directory exists in the current root\n",
    "#         if directory_name in dirs:\n",
    "#             # Construct the full path\n",
    "#             found_path = os.path.join(root, directory_name)\n",
    "#             break  # Exit loop once directory is found\n",
    "\n",
    "#     if found_path:\n",
    "#         print(\"Directory found at:\", found_path)\n",
    "#     else:\n",
    "#         print(f\"Directory '{directory_name}' not found under '{folder_path}'.\")\n",
    "# else:\n",
    "#     print(f\"Folder path '{folder_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_folder_path = folder_path+'/model'\n",
    "# Directory name to check\n",
    "directory_name = final_model_name.replace('-', '_')\n",
    "\n",
    "# Check if folder_path exists\n",
    "if os.path.exists(model_folder_path):\n",
    "    # Variable to store the full path if directory is found\n",
    "    found_path = None\n",
    "    \n",
    "    # Walk through all subdirectories under folder_path\n",
    "    for root, dirs, files in os.walk(model_folder_path):\n",
    "        # Check if the target directory exists in the current root\n",
    "        if directory_name in dirs:\n",
    "            # Construct the full path\n",
    "            found_path = os.path.join(root, directory_name)\n",
    "            break  # Exit loop once directory is found\n",
    "\n",
    "    # If found_path is not set, it means we are in an HPO scenario\n",
    "    if not found_path:\n",
    "        # Check if there is only one model file in the top-level 'models' directory\n",
    "        models_folder = os.path.join(model_folder_path, 'models')\n",
    "        if os.path.exists(models_folder):\n",
    "            model_files = [f for f in os.listdir(models_folder) if os.path.isfile(os.path.join(models_folder, f))]\n",
    "            if len(model_files) == 1:\n",
    "                found_path = models_folder\n",
    "            else:\n",
    "                print(f\"Multiple model files found in '{models_folder}'. Unable to determine final model path.\")\n",
    "                found_path = None\n",
    "\n",
    "        # Additional check if found_path is not set\n",
    "        if not found_path:\n",
    "            # Check for files inside 'model' directory\n",
    "            model_folder = os.path.join(model_folder_path, 'model')\n",
    "            if os.path.exists(model_folder):\n",
    "                model_files = [f for f in os.listdir(model_folder) if os.path.isfile(os.path.join(model_folder, f))]\n",
    "                if model_files:\n",
    "                    found_path = model_folder\n",
    "                    print(f\"Model files found in '{model_folder}': {model_files}\")\n",
    "\n",
    "    if found_path:\n",
    "        print(\"Model directory found at:\", model_folder_path)\n",
    "    else:\n",
    "        print(f\"Directory or model '{directory_name}' not found under '{model_folder_path}'.\")\n",
    "else:\n",
    "    print(f\"Folder path '{model_folder_path}' does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = {}\n",
    "\n",
    "# # Iterate over the candidate metrics\n",
    "# for metric in best_candidate[\"CandidateProperties\"][\"CandidateMetrics\"]:\n",
    "#     # Check if the metric is RMSE or F1 and store the corresponding value\n",
    "#     if metric['MetricName'] == 'RMSE':\n",
    "#         score['RMSE'] = metric['Value']\n",
    "#     elif metric['MetricName'] == 'F1':\n",
    "#         score['F1'] = metric['Value']\n",
    "\n",
    "# Initialize the score dictionary\n",
    "score = {}\n",
    "\n",
    "# Initialize the score dictionary\n",
    "score = {}\n",
    "\n",
    "# Extract problem type from the job description\n",
    "problem_type = job_desc['ResolvedAttributes']['AutoMLProblemTypeResolvedAttributes']['TabularResolvedAttributes']['ProblemType']\n",
    "print(problem_type)\n",
    "# Iterate over the candidate metrics\n",
    "for metric in best_candidate[\"CandidateProperties\"][\"CandidateMetrics\"]:\n",
    "    # Store specific metrics based on problem type\n",
    "    if problem_type == 'Regression':\n",
    "        if metric['MetricName'] == 'RMSE':\n",
    "            score['RMSE'] = metric['Value']\n",
    "    elif problem_type == 'BinaryClassification':\n",
    "        if metric['MetricName'] == 'F1':\n",
    "            score['F1'] = metric['Value']\n",
    "    elif problem_type == 'MulticlassClassification':\n",
    "        if metric['MetricName'] == 'F1macro':\n",
    "            score['F1macro'] = metric['Value']\n",
    "\n",
    "# Print or return the score dictionary\n",
    "print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving All Model Metric in Local Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model_metrics= pd.DataFrame(best_candidate[\"CandidateProperties\"][\"CandidateMetrics\"])\n",
    "file_path = f'{folder_path}/model_metrics.csv'\n",
    "model_metrics.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dashbaord for Online Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_name = cube_name + '_' + table.split('.')[0] + '_sagemaker'\n",
    "dashboard_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if dashbaord exsists\n",
    "url = 'http://' + os.environ['API_GATEWAY_EXTERNAL_SERVICE_HOST'] + ':' + os.environ['API_GATEWAY_EXTERNAL_SERVICE_PORT']\n",
    "endpoint = f'/api/v1/dashboards?datasourceTitle={cube_name}'\n",
    "# endpoint = f'{url}/api/v1/dashboards?datasourceTitle={cube_name}'\n",
    "\n",
    "# source_token = ''\n",
    "# source_head = {'Authorization': f'Bearer {source_token}','Content-type': 'application/json'}\n",
    "# response = requests.get(endpoint, headers=source_head)\n",
    "response = sisense_conn.call_api_custom('GET',url,endpoint, params=None, payload=None)\n",
    "response\n",
    "res = response.json()\n",
    "dashboard_exists = False\n",
    "dash_id = ''\n",
    "# Check if the dashboard already exists\n",
    "for dash in res:\n",
    "    if dash['title'] == dashboard_name:\n",
    "        dashboard_exists = True\n",
    "        dash_id = dash['oid']\n",
    "        print(f\"Dashboard '{dashboard_name}' - '{dash_id}' Already Exists\")\n",
    "        break\n",
    "\n",
    "# If the dashboard does not exist, create it\n",
    "if not dashboard_exists:\n",
    "    print(f'Creating Dashboard as {dashboard_name}')\n",
    "    payload = {\n",
    "        \"title\": dashboard_name,\n",
    "        \"datasource\": {\n",
    "            \"fullname\": f\"localhost/{cube_name}\",\n",
    "            \"id\": f\"localhost_{cube_name}\",\n",
    "            \"address\": \"LocalHost\",\n",
    "            \"database\": cube_name,\n",
    "            \"live\": False,\n",
    "            \"title\": cube_name\n",
    "        },\n",
    "        \"type\": \"dashboard\",\n",
    "        \"desc\": \"\",\n",
    "        \"filters\": [],\n",
    "        \"style\": {},\n",
    "        \"editing\": True\n",
    "    }\n",
    "\n",
    "    dash_endpoint = f'/api/dashboards/'\n",
    "    # response = requests.post(dash_endpoint, headers=source_head, data=json.dumps(payload))\n",
    "    response = sisense_conn.call_api_custom('POST',url,dash_endpoint, params=None, payload=payload)\n",
    "    res=response.json()\n",
    "    dash_id = res[0]['oid']\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Dashboard '{dashboard_name}' - '{dash_id}' created successfully\")\n",
    "    else:\n",
    "        print(f'Failed to create dashboard {dashboard_name}. Status code: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Widget Payload \n",
    "def generate_payload(features):\n",
    "    columns = []\n",
    "    num_columns = 3\n",
    "    items_per_column = len(features) // num_columns\n",
    "    extra_items = len(features) % num_columns\n",
    "    \n",
    "    feature_index = 0\n",
    "\n",
    "    for col in range(num_columns):\n",
    "        column = {\n",
    "            \"type\": \"Column\",\n",
    "            \"separator\": col == 0,  # Only the first column has separator set to True\n",
    "            \"spacing\": \"large\",\n",
    "            \"items\": []\n",
    "        }\n",
    "\n",
    "        for item in range(items_per_column + (1 if col < extra_items else 0)):\n",
    "            feature = features[feature_index]\n",
    "            item_dict = {\n",
    "                \"spacing\": \"large\",\n",
    "                \"type\": \"Input.Text\",\n",
    "                \"id\": f\"data.{feature}\",\n",
    "                \"placeholder\": feature,\n",
    "                \"defaultValue\": \"\",\n",
    "                \"isMultiline\": True,\n",
    "                \"rows\": \"2\",\n",
    "                \"borderRadius\": \"14px\",\n",
    "                \"borderStyle\": \"none\",\n",
    "                \"backgroundColor\": \"lightgrey\"\n",
    "            }\n",
    "            column[\"items\"].append(item_dict)\n",
    "            feature_index += 1\n",
    "\n",
    "        columns.append(column)\n",
    "\n",
    "    payload = {\n",
    "        \"columns\": columns\n",
    "    }\n",
    "\n",
    "    # return json.dumps(payload, indent=4)\n",
    "    return payload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if widget exists\n",
    "# widget_endpoint = f'{url}/api/v1/dashboards/{dash_id}/widgets'\n",
    "# response = requests.get(widget_endpoint, headers=source_head)\n",
    "widget_endpoint = f'/api/v1/dashboards/{dash_id}/widgets'\n",
    "response = sisense_conn.call_api_custom('GET',url,widget_endpoint, params=None, payload=None)\n",
    "res = response.json()\n",
    "widget_id = ''\n",
    "widget_exists = False\n",
    "\n",
    "# Check if the widget already exists\n",
    "for widget in res:\n",
    "    if widget['title'] == table.split('.')[0] + '_sagemaker_online_prediction':\n",
    "        widget_exists = True\n",
    "        widget_id= widget[\"oid\"]\n",
    "        print(f\"Widget {widget_id} 'Online-Prediction' in '{dashboard_name}' Already Exists\")\n",
    "        break\n",
    "\n",
    "# If the widget does not exist, create it\n",
    "if not widget_exists:\n",
    "    print(f'Creating Widget in {dashboard_name}')\n",
    "    payload = {\n",
    "    \"title\": table.split('.')[0] + '_sagemaker_online_prediction',\n",
    "    \"type\": \"BloX\",\n",
    "    \"subtype\": \"BloX\",\n",
    "    \"desc\": None,\n",
    "    \"source\": None,\n",
    "    \"datasource\": {\n",
    "        \"title\": cube_name,\n",
    "        \"fullname\": f'LocalHost/{cube_name}',\n",
    "        \"id\": f'LOCALHOST_{cube_name}',\n",
    "        \"address\": \"LocalHost\",\n",
    "        \"database\": cube_name\n",
    "    },\n",
    "    \"selection\": None,\n",
    "    \"metadata\": {\n",
    "        \"ignore\": {\n",
    "            \"dimensions\": [],\n",
    "            \"ids\": [],\n",
    "            \"all\": False\n",
    "        },\n",
    "        \"panels\": [\n",
    "            {\n",
    "                \"name\": \"Items\",\n",
    "                \"items\": []\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Values\",\n",
    "                \"items\": []\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"filters\",\n",
    "                \"items\": []\n",
    "            }\n",
    "        ],\n",
    "        \"usedFormulasMapping\": {}\n",
    "    },\n",
    "    \"style\": {\n",
    "        \"currentCard\": {\n",
    "            \"style\": \"\",\n",
    "            \"script\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"showCarousel\": True,\n",
    "            \"backgroundImage\": \"\",\n",
    "            \"body\": [\n",
    "                {\n",
    "                    \"type\": \"Container\",\n",
    "                    \"items\": [\n",
    "                        {\n",
    "                            \"type\": \"TextBlock\",\n",
    "                            \"text\": \"Sisense AutoML\",\n",
    "                            \"size\": \"extraLarge\",\n",
    "                            \"color\": \"yellow\",\n",
    "                            \"weight\": \"bold\",\n",
    "                            \"horizontalAlignment\": \"center\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"ColumnSet\",\n",
    "                            \"spacing\": \"extraLarge\",\n",
    "                            \"columns\": []\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"Container\",\n",
    "                    \"separator\": False,\n",
    "                    \"id\": \"outputContainer\",\n",
    "                    \"size\": \"Large\",\n",
    "                    \"items\": [\n",
    "                        {\n",
    "                            \"type\": \"ActionSet\",\n",
    "                            \"actions\": [\n",
    "                                {\n",
    "                                    \"type\": \"sagemaker_prediction\",\n",
    "                                    \"title\": \"Predict\",\n",
    "                                    \"data\": {\n",
    "                                        \"question\": \"\",\n",
    "                                        \"table\": \"\"\n",
    "                                    }\n",
    "                                }\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            \"spacing\": \"extraLarge\",\n",
    "                            \"type\": \"TextBlock\",\n",
    "                            \"text\": \"Output \",\n",
    "                            \"color\": \"green\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"currentConfig\": {\n",
    "            \"fontFamily\": \"Open Sans\",\n",
    "            \"fontSizes\": {\n",
    "                \"default\": 16,\n",
    "                \"small\": 12,\n",
    "                \"medium\": 22,\n",
    "                \"large\": 32,\n",
    "                \"extraLarge\": 50\n",
    "            },\n",
    "            \"fontWeights\": {\n",
    "                \"default\": 500,\n",
    "                \"light\": 100,\n",
    "                \"bold\": 900\n",
    "            },\n",
    "            \"containerStyles\": {\n",
    "                \"default\": {\n",
    "                    \"backgroundColor\": \"black\",\n",
    "                    \"foregroundColors\": {\n",
    "                        \"default\": {\n",
    "                            \"normal\": \"#3A4356\"\n",
    "                        },\n",
    "                        \"white\": {\n",
    "                            \"normal\": \"#ffffff\"\n",
    "                        },\n",
    "                        \"grey\": {\n",
    "                            \"normal\": \"#dcdcdc\"\n",
    "                        },\n",
    "                        \"orange\": {\n",
    "                            \"normal\": \"#f2B900\"\n",
    "                        },\n",
    "                        \"yellow\": {\n",
    "                            \"normal\": \"#ffcb05\"\n",
    "                        },\n",
    "                        \"black\": {\n",
    "                            \"normal\": \"#000000\"\n",
    "                        },\n",
    "                        \"lightGreen\": {\n",
    "                            \"normal\": \"#93c0c0\"\n",
    "                        },\n",
    "                        \"green\": {\n",
    "                            \"normal\": \"#54a254\"\n",
    "                        },\n",
    "                        \"red\": {\n",
    "                            \"normal\": \"#dd1111\"\n",
    "                        },\n",
    "                        \"accent\": {\n",
    "                            \"normal\": \"#2E89FC\"\n",
    "                        },\n",
    "                        \"good\": {\n",
    "                            \"normal\": \"#54a254\"\n",
    "                        },\n",
    "                        \"warning\": {\n",
    "                            \"normal\": \"#e69500\"\n",
    "                        },\n",
    "                        \"attention\": {\n",
    "                            \"normal\": \"#cc3300\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"imageSizes\": {\n",
    "                \"default\": 40,\n",
    "                \"small\": 40,\n",
    "                \"medium\": 80,\n",
    "                \"large\": 160\n",
    "            },\n",
    "            \"imageSet\": {\n",
    "                \"imageSize\": \"medium\",\n",
    "                \"maxImageHeight\": 100\n",
    "            },\n",
    "            \"actions\": {\n",
    "                \"color\": \"\",\n",
    "                \"backgroundColor\": \"red\",\n",
    "                \"maxActions\": 5,\n",
    "                \"spacing\": \"extraLarge\",\n",
    "                \"buttonSpacing\": 20,\n",
    "                \"actionsOrientation\": \"horizontal\",\n",
    "                \"actionAlignment\": \"center\",\n",
    "                \"showCard\": {\n",
    "                    \"actionMode\": \"inline\",\n",
    "                    \"inlineTopMargin\": 16,\n",
    "                    \"style\": \"default\"\n",
    "                }\n",
    "            },\n",
    "            \"spacing\": {\n",
    "                \"default\": 5,\n",
    "                \"small\": 5,\n",
    "                \"medium\": 10,\n",
    "                \"large\": 20,\n",
    "                \"extraLarge\": 40,\n",
    "                \"padding\": 20\n",
    "            },\n",
    "            \"separator\": {\n",
    "                \"lineThickness\": 1,\n",
    "                \"lineColor\": \"#eeeeee\"\n",
    "            },\n",
    "            \"factSet\": {\n",
    "                \"title\": {\n",
    "                    \"size\": \"default\",\n",
    "                    \"color\": \"default\",\n",
    "                    \"weight\": \"bold\",\n",
    "                    \"warp\": True\n",
    "                },\n",
    "                \"value\": {\n",
    "                    \"size\": \"default\",\n",
    "                    \"color\": \"default\",\n",
    "                    \"weight\": \"default\",\n",
    "                    \"warp\": True\n",
    "                },\n",
    "                \"spacing\": 20\n",
    "            },\n",
    "            \"supportsInteractivity\": True,\n",
    "            \"imageBaseUrl\": \"\",\n",
    "            \"height\": 743\n",
    "        },\n",
    "        \"currentCardName\": \"Multiple Indicator\",\n",
    "        \"narration\": {\n",
    "            \"enabled\": False,\n",
    "            \"display\": \"above\",\n",
    "            \"format\": \"bullets\",\n",
    "            \"verbosity\": \"medium\",\n",
    "            \"up_sentiment\": \"good\",\n",
    "            \"aggregation\": \"sum\",\n",
    "            \"labels\": []\n",
    "        }\n",
    "    }\n",
    "}\n",
    "    payload_columns = generate_payload(widget_features)\n",
    "    payload['style']['currentCard']['body'][0]['items'][1]['columns'] = payload_columns['columns']\n",
    "    # dash_endpoint = f'{url}/api/v1/dashboards/{dash_id}/widgets'\n",
    "    response = sisense_conn.call_api_custom('POST',url,widget_endpoint, params=None, payload=payload)\n",
    "    # response = requests.post(widget_endpoint, headers=source_head, data=json.dumps(payload))\n",
    "    widget_id = response.json()[\"oid\"]\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "        print(f\"Widget '{widget_id}' - '_sagemaker_online_prediction' in '{dashboard_name}' created successfully\")\n",
    "    else:\n",
    "        print(f'Failed to create Widget in \"{dashboard_name}\". Status code: {response.status_code}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create result dataframe for model name and accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metric name and value from score\n",
    "key, value = next(iter(score.items()))\n",
    "df = pd.DataFrame({\n",
    "    'model_name': [model_name],\n",
    "    'metric_name': [key],\n",
    "    'score': [int(value * 100) / 100.0],\n",
    "    'path': [found_path]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model information in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = f\"/opt/sisense/storage/notebooks/custom_code_notebooks/notebooks/automl/models/\"\n",
    "# os.makedirs(folder_path, exist_ok=True)\n",
    "new_df = df.copy()\n",
    "new_df['provider'] = 'Sagemaker'\n",
    "new_df['created_date'] = datetime.now()\n",
    "new_df['dash_id'] = dash_id\n",
    "new_df['widget_id'] = widget_id\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_file_path = f\"/opt/sisense/storage/notebooks/custom_code_notebooks/notebooks/automl/models/models.csv\"\n",
    "# Check if models.csv file exists\n",
    "if not os.path.exists(models_file_path):\n",
    "    # If it does not exist, create an empty DataFrame and save it as models.csv\n",
    "    empty_df = pd.DataFrame(columns=new_df.columns)\n",
    "    empty_df.to_csv(models_file_path, index=False)\n",
    "    print('empty')\n",
    "old_df = pd.read_csv(models_file_path)\n",
    "if old_df.empty:\n",
    "    combined_df = new_df\n",
    "else:\n",
    "    combined_df = pd.concat([old_df, new_df], axis=0)\n",
    "\n",
    "combined_df.to_csv(models_file_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create AWS Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestamp_suffix = strftime(\"%Y%m%d%H%M%S\", gmtime())\n",
    "endpoint_config_name = model_name + \"-\" + timestamp_suffix + \"-epc\"\n",
    "endpoint_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(endpoint_config_name) > 63:\n",
    "    # Calculate how many characters need to be trimmed from model_name\n",
    "    excess_length = len(endpoint_config_name) - 63\n",
    "    # Trim the model_name to make it fit within the limit\n",
    "    model_name_trimmed = model_name[excess_length:]\n",
    "    # Recreate the endpoint_config_name with the trimmed model_name\n",
    "    endpoint_config_name = model_name_trimmed + \"-\" + timestamp_suffix + \"-epc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Endpoint Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if sagemaker used Ensemble or HPO based on dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(best_candidate[\"InferenceContainers\"]) > 1:\n",
    "    mode_selected = 'HPO'\n",
    "else:\n",
    "    mode_selected = 'Ensemble'\n",
    "mode_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = s3.head_object(Bucket=S3_bucket_name, Key=s3_key)\n",
    "# file_size = response['ContentLength']\n",
    "# file_size_mb = file_size / (1024 * 1024)\n",
    "# if file_size_mb > 100:\n",
    "#     mode_selected = 'HPO'\n",
    "# else:\n",
    "#     mode_selected = 'Ensemble'\n",
    "# mode_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode_selected == 'HPO':\n",
    "    ## Creating provisioned endpoint configuration\n",
    "    endpoint_config = autopilot.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                'VariantName': 'AllTraffic',\n",
    "                'ModelName': model_name,\n",
    "                'InstanceType': 'ml.m5.large',\n",
    "                'InitialInstanceCount': 1\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "else:\n",
    "    # Creating serverless endpoint configuration\n",
    "    serverless_config = {\n",
    "        'MemorySizeInMB': 1024,\n",
    "        'MaxConcurrency': 5\n",
    "    }\n",
    "    endpoint_config = autopilot.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                'VariantName': 'AllTraffic',\n",
    "                'ModelName': model_name,\n",
    "                'ServerlessConfig': serverless_config\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "endpoint_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = endpoint_config_name.replace('-epc', '-ep')\n",
    "create_endpoint_response = autopilot.create_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wait for Endpoint to be created\n",
    "autopilot.get_waiter(\"endpoint_in_service\").wait(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe endpoint creation status\n",
    "status = autopilot.describe_endpoint(EndpointName=endpoint_name)[\"EndpointStatus\"]\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # once endpoint status is InService, you can invoke the endpoint for inferencing\n",
    "# # Define your input data as a CSV string\n",
    "# input_data = \"1000,101113,2019011,9039658401,1,1,ZA,2019-11-26T00:00:00,2019-11-26T00:00:00,2020-01-25T00:00:00,2020-01-25T00:00:00,AA,USD,888005002.69,Open,NET060,GL001\"\n",
    "# # input_data = \"Lucchese,586,France,Female,23.0,2,0.0,2,0.0,1.0,160976.75\"\n",
    "# if status == \"InService\":\n",
    "#     # region_name = 'us-east-1'\n",
    "#     sm_runtime = boto3.client('sagemaker-runtime', region_name=region_name)\n",
    "#     inference_result = sm_runtime.invoke_endpoint(EndpointName=endpoint_name, ContentType='text/csv', Body=input_data)\n",
    "# inference_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_result = inference_result['Body'].read().decode('utf-8').strip()\n",
    "# inference_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if inference_result is not empty\n",
    "# if inference_result:\n",
    "#     try:\n",
    "#         # Convert the prediction to a float\n",
    "#         prediction_value = float(inference_result)\n",
    "\n",
    "#         # Check if the float is very close to an integer\n",
    "#         if prediction_value.is_integer():\n",
    "#             # Convert to int if it is close enough to an integer\n",
    "#             prediction = int(prediction_value)\n",
    "#         else:\n",
    "#             # Otherwise, keep as float\n",
    "#             prediction = prediction_value\n",
    "\n",
    "#         print(\"Prediction:\", prediction)\n",
    "#     except ValueError as e:\n",
    "#         print(f\"Error converting prediction to float: {e}\")\n",
    "# else:\n",
    "#     print(\"Error: Inference result is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### OLD METHOD FOR INFERENCE ######\n",
    "\n",
    "# from io import StringIO\n",
    "\n",
    "# if sagemaker.__version__ < \"2\":\n",
    "#     from sagemaker.predictor import RealTimePredictor\n",
    "#     from sagemaker.content_types import CONTENT_TYPE_CSV\n",
    "\n",
    "#     predictor = RealTimePredictor(\n",
    "#         endpoint=endpoint_name,\n",
    "#         sagemaker_session=session,\n",
    "#         content_type=CONTENT_TYPE_CSV,\n",
    "#         accept=CONTENT_TYPE_CSV,\n",
    "#     )\n",
    "\n",
    "#     # Obtain predictions from SageMaker endpoint\n",
    "#     prediction = predictor.predict(\n",
    "#         open_ar.to_csv(sep=\",\", header=False, index=False)\n",
    "#     ).decode(\"utf-8\")\n",
    "\n",
    "#     # Load prediction in pandas and compare to ground truth\n",
    "#     prediction_df = pd.read_csv(StringIO(prediction), header=None)\n",
    "\n",
    "# else:\n",
    "#     from sagemaker.predictor import Predictor\n",
    "#     from sagemaker.serializers import CSVSerializer\n",
    "#     from sagemaker.deserializers import CSVDeserializer\n",
    "    \n",
    "#     predictor = Predictor(\n",
    "#         endpoint_name=endpoint_name,\n",
    "#         sagemaker_session=session,\n",
    "#         serializer=CSVSerializer(),\n",
    "#         deserializer=CSVDeserializer(),\n",
    "#     )\n",
    "    \n",
    "#     # Obtain predictions from SageMaker endpoint\n",
    "#     single_row_values = \"-122.23,37.88,45,500,120,400,135,8.20,NEAR BAY\"\n",
    "#     prediction = predictor.predict(single_row_values)\n",
    "#     # Load prediction in pandas\n",
    "#     prediction_df = pd.DataFrame(prediction)\n",
    "# prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model and Endpoint Name information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if endpoint_name is defined\n",
    "try:\n",
    "    endpoint_name = endpoint_name \n",
    "except NameError:\n",
    "    endpoint_name = \"\" \n",
    "\n",
    "fdf = pd.DataFrame({\n",
    "    'model_name': [model_name],\n",
    "    'metric_name': [key],\n",
    "    'score': [int(value * 100) / 100.0],\n",
    "    'local_path': [found_path],\n",
    "    'model_s3_location': [model_location],\n",
    "    'aws_model_name': [final_model_name],\n",
    "    'endpoint_name': [endpoint_name]\n",
    "})\n",
    "fdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save endpoint information locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_value = fdf[\"endpoint_name\"].iloc[0]  # This extracts the single value from the column\n",
    "\n",
    "# Construct the full file path\n",
    "endpoint_file_path = os.path.join(folder_path, \"endpoint.txt\")\n",
    "\n",
    "# Save the value to the specified directory\n",
    "with open(endpoint_file_path, \"w\") as file:\n",
    "    file.write(endpoint_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(fdf)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Model, Endpoint Config, Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autopilot.delete_endpoint(EndpointName=endpoint_name) \n",
    "# autopilot.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "# autopilot.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = autopilot.list_models()\n",
    "\n",
    "# # Print out all models and delete them\n",
    "# for model in response[\"Models\"]:\n",
    "#     print(f\"Model Name: {model['ModelName']}, Creation Time: {model['CreationTime']}\")\n",
    "#     autopilot.delete_model(ModelName=model['ModelName'])\n",
    "#     print(f\"{model['ModelName']} deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
