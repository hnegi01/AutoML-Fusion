{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Cell\n",
    "# When the notebook is executed by the widget, this cell is ignored.\n",
    "\n",
    "# import pandas as pd\n",
    "# import sys\n",
    "# import os\n",
    "# import base64\n",
    "# import io\n",
    "\n",
    "## Iis\n",
    "#additional_parameters =  '{\"input\":{\"question\":\"\",\"table\":\"\",\"SepalLengthCm\":\"12\",\"SepalWidthCm\":\"43\",\"PetalLengthCm\":\"33\",\"PetalWidthCm\":\"31\",\"widget\":\"Iris_Online-Prediction\"},\"cookie\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoiNjIyOGRiOTFiYTEwYWQwMDJkOTZjNTE4IiwiYXBpU2VjcmV0IjoiNDZjZDk3YjEtOTRmMi0yNjE4LTI5MGQtMWU1Y2M3NzQxY2QwIiwiYWxsb3dlZFRlbmFudHMiOlsiNjIwMTIzYTFiYzBhMWUwMDFhNTlkMjQ5Il0sInRlbmFudElkIjoiNjIwMTIzYTFiYzBhMWUwMDFhNTlkMjQ5IiwiZXhwIjoxNzI0MDgwMTU4fQ.HVwWASrVaH1ckM7pJ4nNyzrBQoWea3oEXkMgbtoIU0c\"}'\n",
    "\n",
    "# Churn\n",
    "additional_parameters = '{\"input\":{\"question\":\"\",\"table\":\"\",\"RowNumber\":\"1\",\"CustomerId\":\"13\",\"Surname\":\"Hill\",\"CreditScore\":\"620\",\"Geography\":\"France\",\"Gender\":\"Male\",\"Age\":\"23\",\"Tenure\":\"5\",\"Balance\":\"23535\",\"NumOfProducts\":\"3\",\"HasCrCard\":\"1\",\"IsActiveMember\":\"1\",\"EstimatedSalary\":\"134255\",\"widget\":\"churn_auto_sklearn_online_prediction\"},\"cookie\":\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoiNjIyOGRiOTFiYTEwYWQwMDJkOTZjNTE4IiwiYXBpU2VjcmV0IjoiNDZjZDk3YjEtOTRmMi0yNjE4LTI5MGQtMWU1Y2M3NzQxY2QwIiwiYWxsb3dlZFRlbmFudHMiOlsiNjIwMTIzYTFiYzBhMWUwMDFhNTlkMjQ5Il0sInRlbmFudElkIjoiNjIwMTIzYTFiYzBhMWUwMDFhNTlkMjQ5IiwiZXhwIjoxNzI0NDQ4OTM1fQ.-38xVywh9MAW7rYE8K52VgHYxaYjvjPJs8PSd5GKYSY\"}'\n",
    "\n",
    "## Housing\n",
    "#additional_parameters = '{\\\"input\\\":{\\\"question\\\":\\\"\\\",\\\"table\\\":\\\"\\\",\\\"longitude\\\":\\\"3314\\\",\\\"latitude\\\":\\\"13431\\\",\\\"housing_median_age\\\":\\\"143\\\",\\\"total_rooms\\\":\\\"134\\\",\\\"total_bedrooms\\\":\\\"142\\\",\\\"population\\\":\\\"134\\\",\\\"households\\\":\\\"421\\\",\\\"median_income\\\":\\\"43\\\",\\\"ocean_proximity\\\":\\\"NEAR BAY\\\",\\\"widget\\\":\\\"housing_Online-Prediction\\\"},\\\"cookie\\\":\\\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoiNjIwMTIzYTFiYzBhMWUwMDFhNTlkMjNjIiwiYXBpU2VjcmV0IjoiMWZjOGE1YjEtYWRlMi0wMTg1LTQ5ZDEtN2FkOTdlNGY0NTljIiwiYWxsb3dlZFRlbmFudHMiOlsiNjIwMTIzYTFiYzBhMWUwMDFhNTlkMjQ5Il0sInRlbmFudElkIjoiNjIwMTIzYTFiYzBhMWUwMDFhNTlkMjQ5IiwiZXhwIjoxNzIxOTM2MzI0fQ.IrSYpDnbv0DmbRDVvaPYATbWsS_tJ1kCsbHuNcB9CIk\\\"}'\n",
    "\n",
    "## AR\n",
    "#additional_parameters = \"{\\\"input\\\":{\\\"question\\\":\\\"\\\",\\\"table\\\":\\\"\\\",\\\"COMP_CODE\\\":\\\"1000\\\",\\\"CUSTOMER\\\":\\\"101113\\\",\\\"FISCPER\\\":\\\"2019011\\\",\\\"DOC_NUMBER\\\":\\\"9039658401\\\",\\\"LINE_ITEM\\\":\\\"1\\\",\\\"SUB_ITEM\\\":\\\"1\\\",\\\"DOC_TYPE\\\":\\\"ZA\\\",\\\"POSTING_DATE\\\":\\\"2019-11-26T00:00:00\\\",\\\"DOC_DATE\\\":\\\"2019-11-26T00:00:00\\\",\\\"NETDUE_DATE\\\":\\\"2020-01-25T00:00:00\\\",\\\"CLEAR_DATE\\\":\\\"\\\",\\\"CUST_CRE_REP_GRP\\\":\\\"AA\\\",\\\"LOCAL_CURRENCY\\\":\\\"USD\\\",\\\"AMOUNT\\\":\\\"552.69\\\",\\\"ITEM_STATUS\\\":\\\"Open\\\",\\\"PAYMENT_TERMS\\\":\\\"NET060\\\",\\\"GL_ACCOUNT\\\":\\\"GL001\\\",\\\"widget\\\":\\\"closed_ar_auto_sklearn_online_prediction\\\"},\\\"cookie\\\":\\\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoiNjIyOGRiOTFiYTEwYWQwMDJkOTZjNTE4IiwiYXBpU2VjcmV0IjoiNDZjZDk3YjEtOTRmMi0yNjE4LTI5MGQtMWU1Y2M3NzQxY2QwIiwiYWxsb3dlZFRlbmFudHMiOlsiNjIwMTIzYTFiYzBhMWUwMDFhNTlkMjQ5Il0sInRlbmFudElkIjoiNjIwMTIzYTFiYzBhMWUwMDFhNTlkMjQ5IiwiZXhwIjoxNzI0Nzc0NzY0fQ.FRuTvZViwtc9y2TI35NfQlqHN4VGAR1M74lrr7XZgKk\\\"}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get install swig -y\n",
    "# !pip install Cython\n",
    "# !pip install scikit-learn #==0.24.0\n",
    "# !pip install auto-sklearn\n",
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON string\n",
    "try:\n",
    "    data = json.loads(additional_parameters)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Failed to parse outer JSON: {e}\")\n",
    "    raise\n",
    "input_data = data[\"input\"]\n",
    "type(input_data)\n",
    "input_data\n",
    "df = pd.DataFrame([input_data])\n",
    "\n",
    "df = df.iloc[:, 2:]\n",
    "df.replace('', np.nan, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = str(df.iloc[0]['widget'])\n",
    "model_folder = model_folder.split('_auto_sklearn_online_prediction')[0]\n",
    "model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setting path\n",
    "\n",
    "model_dir = f'/opt/sisense/storage/notebooks/custom_code_notebooks/notebooks/automl/{model_folder}' \n",
    "\n",
    "# List all directories under model_dir\n",
    "all_dirs = os.listdir(model_dir)\n",
    "\n",
    "# Filter directories based on date format\n",
    "date_format = \"%Y%m%d%H%M%S\"\n",
    "date_dirs = [d for d in all_dirs if len(d) == 14 and d.isdigit()]  # Filter by length and digits\n",
    "\n",
    "# Parse directory names into datetime objects\n",
    "date_objs = [datetime.strptime(d, date_format) for d in date_dirs]\n",
    "\n",
    "# Find the latest date\n",
    "latest_date = max(date_objs)\n",
    "\n",
    "# Convert latest date back to string format\n",
    "latest_date_str = latest_date.strftime(date_format)\n",
    "\n",
    "# Construct full path to the latest directory\n",
    "latest_path = os.path.join(model_dir, latest_date_str)\n",
    "\n",
    "print(\"Latest directory:\", latest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Numeric and Categorical column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Numeric Columns\n",
    "numeric_columns = joblib.load(f\"{latest_path}/numeric_column_list\")\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Categorical Columns\n",
    "categorical_columns = joblib.load(f\"{latest_path}/categorical_column_list\")\n",
    "categorical_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Date Columns\n",
    "try:\n",
    "    date_columns = joblib.load(f\"{latest_path}/date_column_list\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load date columns: {e}\")\n",
    "    print(\"Setting list as empty\")\n",
    "    date_columns = []\n",
    "date_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data Types of new data to modeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the list and convert each column in df to datetime, then to year and month\n",
    "for col in date_columns:\n",
    "    # Check if the column exists in the DataFrame\n",
    "    if col in df.columns:\n",
    "        # Convert to datetime if not already done\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        \n",
    "        # Create new columns for year and month\n",
    "        df[col + '_YEAR'] = df[col].dt.year.astype(str)\n",
    "        df[col + '_MONTH'] = df[col].dt.month.astype(str)\n",
    "        \n",
    "        # Drop the original date column\n",
    "        df.drop(columns=[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categorical_columns:\n",
    "    df[column] = df[column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numeric_columns:\n",
    "    # Attempt to convert to integer, but handle cases where the value is a float\n",
    "    try:\n",
    "        # Try converting the column to float first\n",
    "        converted = pd.to_numeric(df[column])\n",
    "        if all(converted % 1 == 0):  # Check if all values are integers\n",
    "            df[column] = converted.astype(int)\n",
    "        else:\n",
    "            df[column] = converted\n",
    "    except ValueError:\n",
    "        # If conversion to float fails, keep the column as is\n",
    "        pass\n",
    "else:\n",
    "    df[column] = df[column].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Feature Data Order to feed transfrom pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load feature data column order\n",
    "feature_columns = joblib.load(f\"{latest_path}/feature_column_order\")\n",
    "feature_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column order of new data\n",
    "df = df[feature_columns]\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Transformer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pipeline\n",
    "transformer_pipeline = joblib.load(f\"{latest_path}/transformer_pipeline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features = transformer_pipeline.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformer_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the model file starting with 'automl' in the latest subdirectory\n",
    "model_files = glob.glob(os.path.join(latest_path, 'automl*'))\n",
    "\n",
    "if model_files:\n",
    "    model_file = model_files[0]\n",
    "    \n",
    "    # Load the model\n",
    "    trained_model = joblib.load(model_file)\n",
    "    print(f\"Loaded model from: {model_file}\")\n",
    "else:\n",
    "    print(\"No model file found starting with 'automl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = trained_model.predict(encoded_features)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"prediction\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"prediction\"] = df_result[\"prediction\"].apply(\n",
    "    lambda x: f\"{x:.2f}\" if isinstance(x, float) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This needs to changed/added based on your ML Use Case!!!\n"
    "if model_folder == 'closed_ar':\n",
    "    df_result[\"prediction\"] = np.where(df_result[\"prediction\"]==0, 'This Accounts Receivable Reciept will be paid Early',\n",
    "                            np.where(df_result[\"prediction\"]==1, 'This Accounts Receivable Reciept will be paid On-Time',\n",
    "                            np.where(df_result[\"prediction\"]==2, 'This Accounts Receivable Reciept will be paid Late', np.nan)))\n",
    "elif model_folder == 'churn' or model_folder == 'bank_churn_train':\n",
    "    df_result[\"prediction\"] = np.where(df_result[\"prediction\"]==0, 'Retained',\n",
    "                            np.where(df_result[\"prediction\"]==1, 'Churned', np.nan))  \n",
    "else:\n",
    "    df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
